# -*- coding: utf-8 -*-
"""
Exemplo de Integra√ß√£o com o Dataset 3W da Petrobras

Este notebook demonstra como usar o m√≥dulo de integra√ß√£o 3W
para carregar e processar dados de detec√ß√£o de anomalias em po√ßos offshore.
"""

import logging
import sys
from pathlib import Path

import marimo as mo
import numpy as np

# Importa os m√≥dulos do projeto
from src.data.data_loader import create_data_loader
from src.data.preprocessing import TimeSeriesPreprocessor
from src.data.threew_dataset import ThreeWDataset, get_threew_info

# Configura logging
logging.basicConfig(level=logging.INFO)

# Adiciona o caminho do projeto ao sys.path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# Configura√ß√£o do Marimo
mo.md("# üõ¢Ô∏è Integra√ß√£o com Dataset 3W da Petrobras")
mo.md(
    "Este notebook demonstra a integra√ß√£o com o dataset 3W para detec√ß√£o de anomalias em po√ßos offshore."
)

# Verifica disponibilidade do 3W
mo.md("## üìä Verifica√ß√£o de Disponibilidade do Dataset 3W")

threew_info = get_threew_info()
mo.json(threew_info)

if threew_info["available"]:
    mo.md("‚úÖ Dataset 3W dispon√≠vel!")
else:
    mo.md("‚ùå Dataset 3W n√£o dispon√≠vel. Verifique se o diret√≥rio 3W est√° presente.")
    mo.md("Para usar este notebook, clone o reposit√≥rio 3W da Petrobras.")

# Se o 3W estiver dispon√≠vel, continua com a demonstra√ß√£o
if threew_info["available"]:
    mo.md("## üîß Inicializa√ß√£o dos M√≥dulos")

    # Inicializa o dataset 3W
    try:
        threew_dataset = ThreeWDataset()
        mo.md("‚úÖ Dataset 3W inicializado com sucesso")

        # Mostra informa√ß√µes do dataset
        dataset_info = threew_dataset.get_dataset_info()
        mo.json(dataset_info)

    except Exception as e:
        mo.md(f"‚ùå Erro ao inicializar dataset 3W: {e}")
        threew_dataset = None

    if threew_dataset:
        mo.md("## üìã Problemas Dispon√≠veis")

        # Lista problemas dispon√≠veis
        problems = threew_dataset.list_available_problems()
        mo.md(f"Problemas encontrados: {problems}")

        if problems:
            mo.md("### Detalhes dos Problemas")

            for problem in problems:
                problem_info = threew_dataset.load_problem_config(problem)
                if problem_info:
                    mo.md(f"**{problem}**")
                    mo.md(f"Descri√ß√£o: {problem_info['description'][:200]}...")
                    mo.md(f"Caminho: {problem_info['path']}")
                    mo.md("---")

        mo.md("## üìä Carregamento de Dados")

        # Inicializa o carregador de dados
        try:
            data_loader = create_data_loader(use_threew=True, cache_data=True)
            mo.md("‚úÖ Carregador de dados inicializado")

            # Mostra informa√ß√µes do carregador
            loader_info = data_loader.get_data_info()
            mo.json(loader_info)

        except Exception as e:
            mo.md(f"‚ùå Erro ao inicializar carregador de dados: {e}")
            data_loader = None

        if data_loader and problems:
            mo.md("## üöÄ Demonstra√ß√£o de Carregamento")

            # Tenta carregar dados do primeiro problema dispon√≠vel
            first_problem = problems[0]
            mo.md(f"Tentando carregar dados do problema: **{first_problem}**")

            try:
                # Lista configura√ß√µes de folds dispon√≠veis
                folds_dir = Path(project_root) / "3W" / "dataset" / "folds"
                if folds_dir.exists():
                    fold_files = [f.stem for f in folds_dir.glob("*.csv")]
                    mo.md(f"Configura√ß√µes de folds dispon√≠veis: {fold_files}")

                    if fold_files:
                        # Tenta carregar com a primeira configura√ß√£o
                        first_fold = fold_files[0]
                        mo.md(f"Usando configura√ß√£o de fold: **{first_fold}**")

                        data = data_loader.load_threew_problem(
                            problem_name=first_problem,
                            fold_config=first_fold,
                            fold_index=0,
                            normalize=True,
                            test_size=0.2,
                        )

                        if data:
                            mo.md("‚úÖ Dados carregados com sucesso!")

                            # Mostra informa√ß√µes dos dados
                            data_summary = {
                                "Problema": data["problem_name"],
                                "Configura√ß√£o de Fold": data["fold_config"],
                                "√çndice do Fold": data["fold_index"],
                                "Forma X_train": str(data["X_train"].shape),
                                "Forma y_train": str(data["y_train"].shape),
                                "Forma X_val": str(data["X_val"].shape),
                                "Forma y_val": str(data["y_val"].shape),
                                "Forma X_test": str(data["X_test"].shape),
                                "Forma y_test": str(data["y_test"].shape),
                                "Normalizado": data["normalized"],
                            }

                            mo.json(data_summary)

                            # Estat√≠sticas b√°sicas
                            mo.md("### üìà Estat√≠sticas dos Dados")

                            # Distribui√ß√£o das classes
                            unique_train, counts_train = np.unique(
                                data["y_train"], return_counts=True
                            )
                            unique_val, counts_val = np.unique(
                                data["y_val"], return_counts=True
                            )
                            unique_test, counts_test = np.unique(
                                data["y_test"], return_counts=True
                            )

                            class_distribution = {
                                "Treino": dict(
                                    zip(unique_train.astype(str), counts_train.tolist())
                                ),
                                "Valida√ß√£o": dict(
                                    zip(unique_val.astype(str), counts_val.tolist())
                                ),
                                "Teste": dict(
                                    zip(unique_test.astype(str), counts_test.tolist())
                                ),
                            }

                            mo.json(class_distribution)

                            # Estat√≠sticas das features
                            X_train_stats = {
                                "M√©dia": np.mean(data["X_train"], axis=0).tolist(),
                                "Desvio Padr√£o": np.std(
                                    data["X_train"], axis=0
                                ).tolist(),
                                "M√≠nimo": np.min(data["X_train"], axis=0).tolist(),
                                "M√°ximo": np.max(data["X_train"], axis=0).tolist(),
                            }

                            mo.md("### üìä Estat√≠sticas das Features (primeiras 5)")
                            mo.json({k: v[:5] for k, v in X_train_stats.items()})

                        else:
                            mo.md("‚ùå Falha ao carregar dados")

                else:
                    mo.md("‚ùå Diret√≥rio de folds n√£o encontrado")

            except Exception as e:
                mo.md(f"‚ùå Erro ao carregar dados: {e}")

        mo.md("## üßπ Pr√©-processamento de Dados")

        # Demonstra o pr√©-processador
        try:
            preprocessor = TimeSeriesPreprocessor(
                imputation_strategy="mean",
                scaling_method="robust",
                feature_selection_method="mutual_info",
                n_features=10,  # Seleciona top 10 features
                pca_components=5,  # Reduz para 5 componentes
            )

            mo.md("‚úÖ Pr√©-processador criado")

            # Se temos dados, aplica o pr√©-processamento
            if "data" in locals() and data:
                mo.md("### üîÑ Aplicando Pr√©-processamento")

                # Ajusta o pr√©-processador
                X_train_processed = preprocessor.fit_transform(
                    data["X_train"], data["y_train"]
                )
                X_val_processed = preprocessor.transform(data["X_val"])
                X_test_processed = preprocessor.transform(data["X_test"])

                mo.md("‚úÖ Pr√©-processamento aplicado com sucesso!")

                # Mostra informa√ß√µes do pr√©-processamento
                preprocessing_info = preprocessor.get_preprocessing_info()
                mo.json(preprocessing_info)

                # Compara formas antes e depois
                comparison = {
                    "Original": {
                        "X_train": str(data["X_train"].shape),
                        "X_val": str(data["X_val"].shape),
                        "X_test": str(data["X_test"].shape),
                    },
                    "Processado": {
                        "X_train": str(X_train_processed.shape),
                        "X_val": str(X_val_processed.shape),
                        "X_test": str(X_test_processed.shape),
                    },
                }

                mo.json(comparison)

        except Exception as e:
            mo.md(f"‚ùå Erro no pr√©-processamento: {e}")

        mo.md("## üìù Resumo da Integra√ß√£o")

        integration_summary = {
            "Dataset 3W": "‚úÖ Integrado com sucesso",
            "Carregamento de Dados": "‚úÖ Funcionando",
            "Pr√©-processamento": "‚úÖ Implementado",
            "Problemas Dispon√≠veis": len(problems) if "problems" in locals() else 0,
            "Cache de Dados": "‚úÖ Habilitado",
            "Normaliza√ß√£o": "‚úÖ Implementada",
            "Sele√ß√£o de Features": "‚úÖ Implementada",
            "Redu√ß√£o de Dimensionalidade": "‚úÖ PCA implementado",
        }

        mo.json(integration_summary)

        mo.md("## üéØ Pr√≥ximos Passos")
        mo.md("""
        Com a integra√ß√£o funcionando, voc√™ pode:

        1. **Treinar modelos de ML**: Use os dados carregados para treinar modelos de detec√ß√£o de anomalias
        2. **Experimentar com diferentes problemas**: Teste diferentes configura√ß√µes de folds e problemas
        3. **Implementar novos modelos**: Adicione novos algoritmos ao projeto
        4. **Otimizar hiperpar√¢metros**: Use t√©cnicas como Optuna para otimiza√ß√£o
        5. **Avaliar performance**: Compare diferentes abordagens usando m√©tricas apropriadas
        """)

else:
    mo.md("## ‚ö†Ô∏è Configura√ß√£o Necess√°ria")
    mo.md("""
    Para usar este notebook, voc√™ precisa:

    1. **Clonar o reposit√≥rio 3W**:
       ```bash
       git clone https://github.com/petrobras/3W.git
       ```

    2. **Colocar o diret√≥rio 3W na raiz do projeto**

    3. **Instalar depend√™ncias do 3W**:
       ```bash
       cd 3W
       conda env create -f environment.yml
       conda activate 3W
       ```

    4. **Voltar ao projeto principal e executar este notebook**
    """)

mo.md("## üìö Documenta√ß√£o Adicional")
mo.md("""
- [README do Projeto 3W](https://github.com/petrobras/3W)
- [Estrutura do Dataset](https://github.com/petrobras/3W/blob/main/3W_DATASET_STRUCTURE.md)
- [Estrutura do Toolkit](https://github.com/petrobras/3W/blob/main/3W_TOOLKIT_STRUCTURE.md)
- [Guia de Contribui√ß√£o](https://github.com/petrobras/3W/blob/main/CONTRIBUTING.md)
""")
