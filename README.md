# ğŸ›¢ï¸ Petrobras Offshore Wells Anomaly Detection Control Charts

[![Python](https://img.shields.io/badge/Python-3.11-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Status](https://img.shields.io/badge/Status-Em%20Desenvolvimento-orange.svg)](https://github.com/RafaelAlvesTech/petrobras-offshore-wells-anomaly-detection-control-charts)
[![PIBIC](https://img.shields.io/badge/PIBIC-2025-purple.svg)](https://www.gov.br/cnpq/pt-br/acesso-a-informacao/acoes-e-programas/programas/programas-de-bolsa-de-iniciacao-cientifica)
[![Google Cloud](https://img.shields.io/badge/Google%20Cloud-Platform-blue.svg)](https://cloud.google.com/)

> **DetecÃ§Ã£o de Anomalias em SÃ©ries Temporais Multivariadas de PoÃ§os Offshore da Petrobras utilizando Modelos de Machine Learning Inovadores e GrÃ¡ficos de Controle**

## ğŸ“‹ Ãndice

- [ğŸ¯ VisÃ£o Geral](#-visÃ£o-geral)
- [ğŸš€ Funcionalidades](#-funcionalidades)
- [ğŸ“Š Dataset](#-dataset)
- [ğŸ› ï¸ Tecnologias](#ï¸-tecnologias)
- [â˜ï¸ Google Cloud Platform](#ï¸-google-cloud-platform)
- [ğŸ“ Estrutura do Projeto](#-estrutura-do-projeto)
- [âš¡ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o](#-instalaÃ§Ã£o-e-configuraÃ§Ã£o)
- [ğŸ“ˆ Metodologia](#-metodologia)
- [ğŸ“… Cronograma](#-cronograma)
- [ğŸ¯ Objetivos SMART](#-objetivos-smart)
- [ğŸ”¬ Modelos Implementados](#-modelos-implementados)
- [ğŸ“Š MÃ©tricas de AvaliaÃ§Ã£o](#-mÃ©tricas-de-avaliaÃ§Ã£o)
- [ğŸš€ Deployment](#-deployment)
- [ğŸ“š DocumentaÃ§Ã£o](#-documentaÃ§Ã£o)
- [ğŸ¤ ContribuiÃ§Ã£o](#-contribuiÃ§Ã£o)
- [ğŸ“„ LicenÃ§a](#-licenÃ§a)

## ğŸ¯ VisÃ£o Geral

Este projeto PIBIC foca na **detecÃ§Ã£o de anomalias em operaÃ§Ãµes de poÃ§os de petrÃ³leo offshore**, utilizando modelos inovadores de Machine Learning para analisar sÃ©ries temporais multivariadas complexas. O objetivo Ã© identificar eventos crÃ­ticos como falhas de equipamento e instabilidades de fluxo de forma precoce e precisa.

### ğŸŒŸ Destaques

- ğŸ” **AnÃ¡lise Multivariada**: Processamento de mÃºltiplas variÃ¡veis interdependentes (pressÃ£o, temperatura, vazÃ£o, vibraÃ§Ã£o)
- ğŸ¤– **Modelos SOTA**: ImplementaÃ§Ã£o dos algoritmos mais recentes em detecÃ§Ã£o de anomalias
- ğŸ“Š **GrÃ¡ficos de Controle**: VisualizaÃ§Ã£o avanÃ§ada para monitoramento em tempo real
- â˜ï¸ **Google Cloud**: Treinamento distribuÃ­do e escalÃ¡vel na nuvem

## ğŸš€ Funcionalidades

### âœ… Implementadas
- [ ] AnÃ¡lise exploratÃ³ria de dados (EDA)
- [ ] PrÃ©-processamento e limpeza de dados
- [ ] Engenharia de atributos avanÃ§ada
- [ ] ImplementaÃ§Ã£o de modelos SOTA
- [ ] AvaliaÃ§Ã£o comparativa de performance
- [ ] ProtÃ³tipo de API para inferÃªncia
- [ ] ContainerizaÃ§Ã£o com Docker
- [ ] CI/CD bÃ¡sico com GitHub Actions
- [x] **IntegraÃ§Ã£o com Google Cloud Platform**
- [x] **Treinamento distribuÃ­do na nuvem**
- [x] **Experiment tracking com MLflow**

### ğŸ”„ Em Desenvolvimento
- [ ] Treinamento dos modelos selecionados
- [ ] OtimizaÃ§Ã£o de hiperparÃ¢metros
- [ ] AnÃ¡lise de interpretabilidade

### ğŸ“‹ Planejadas
- [ ] Interface de usuÃ¡rio para monitoramento
- [ ] RelatÃ³rio final PIBIC

## ğŸ“Š Dataset

### Dataset 3W da Petrobras
- **Tipo**: SÃ©ries temporais multivariadas
- **VariÃ¡veis**: PressÃ£o, temperatura, vazÃ£o, vibraÃ§Ã£o
- **CaracterÃ­sticas**:
  - Grande volume de dados
  - Alta dimensionalidade
  - InterdependÃªncia entre variÃ¡veis
  - Eventos anÃ´malos raros e imprevisÃ­veis

### ğŸ¯ Foco Especial
- **Falhas de equipamento**: IdentificaÃ§Ã£o de problemas incipientes
- **Instabilidades de fluxo**: Monitoramento de operaÃ§Ãµes anormais

## ğŸ› ï¸ Tecnologias

### ğŸ Linguagens e Frameworks
- **Python 3.11**: Linguagem principal (versÃ£o LTS)
- **PyTorch/TensorFlow**: Deep Learning
- **Scikit-learn**: Machine Learning tradicional
- **Pandas/NumPy**: ManipulaÃ§Ã£o de dados
- **Polars**: ManipulaÃ§Ã£o de dados de alta performance (alternativa ao Pandas)
- **Matplotlib/Seaborn**: VisualizaÃ§Ã£o
- **Marimo**: Notebooks interativos Python modernos

### â˜ï¸ Google Cloud Platform
- **Vertex AI**: Treinamento e deployment de modelos
- **AI Platform**: Treinamento distribuÃ­do
- **Cloud Storage**: Armazenamento de dados e modelos
- **Cloud Build**: CI/CD automatizado
- **Cloud Run**: Servidor MLflow
- **Cloud Logging & Monitoring**: Observabilidade

### ğŸ“¦ Gerenciamento de DependÃªncias
- **uv**: Gerenciador de pacotes Python moderno e rÃ¡pido
- **pyproject.toml**: ConfiguraÃ§Ã£o centralizada do projeto
- **requirements.txt**: DependÃªncias tradicionais (compatibilidade)

### ğŸ”§ Ferramentas de Desenvolvimento
- **Docker**: ContainerizaÃ§Ã£o
- **Git/GitHub**: Versionamento
- **GitHub Actions**: CI/CD
- **Optuna**: OtimizaÃ§Ã£o de hiperparÃ¢metros
- **PyOD**: DetecÃ§Ã£o de outliers
- **pre-commit**: Hooks de qualidade de cÃ³digo
- **Marimo**: Notebooks interativos e desenvolvimento colaborativo
- **MLflow**: Experiment tracking e model registry

## â˜ï¸ Google Cloud Platform

### ğŸš€ Treinamento DistribuÃ­do

O projeto estÃ¡ configurado para treinamento de modelos na Google Cloud Platform, oferecendo:

- **Escalabilidade**: Treinamento em mÃºltiplas GPUs e mÃ¡quinas
- **Custo-efetividade**: Pagamento apenas pelo uso
- **IntegraÃ§Ã£o**: Seamless integration com MLflow e experiment tracking
- **AutomaÃ§Ã£o**: CI/CD pipeline para treinamento automÃ¡tico

### ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Local Dev     â”‚    â”‚   Google Cloud   â”‚    â”‚   MLflow UI     â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                 â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚   Code      â”‚ â”‚â”€â”€â”€â–¶â”‚ â”‚ Vertex AI    â”‚ â”‚â”€â”€â”€â–¶â”‚ â”‚ Experiments â”‚ â”‚
â”‚ â”‚             â”‚ â”‚    â”‚ â”‚              â”‚ â”‚    â”‚ â”‚             â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                 â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚   Data      â”‚ â”‚â”€â”€â”€â–¶â”‚ â”‚ Cloud Storageâ”‚ â”‚â”€â”€â”€â–¶â”‚ â”‚ Model      â”‚ â”‚
â”‚ â”‚             â”‚ â”‚    â”‚ â”‚              â”‚ â”‚    â”‚ â”‚ Registry   â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”§ ServiÃ§os Utilizados

| ServiÃ§o | PropÃ³sito | ConfiguraÃ§Ã£o |
|---------|-----------|--------------|
| **Vertex AI** | Treinamento e deployment | n1-standard-4 + T4 GPU |
| **AI Platform** | Treinamento distribuÃ­do | Scale tier: BASIC_GPU |
| **Cloud Storage** | Dados e modelos | Bucket com versioning |
| **Cloud Build** | CI/CD pipeline | Build automÃ¡tico |
| **Cloud Run** | MLflow server | 2GB RAM, 1 CPU |
| **Cloud Logging** | Monitoramento | Logs estruturados |

### ğŸ“Š ConfiguraÃ§Ã£o de Treinamento

```yaml
# Exemplo de configuraÃ§Ã£o para LSTM-VAE
training:
  model: lstm_vae
  epochs: 150
  batch_size: 64
  learning_rate: 0.0001
  machine_type: n1-standard-4
  accelerator: NVIDIA_TESLA_T4
  worker_count: 2
```

### ğŸš€ Quick Start

1. **Configurar GCP**:
   ```bash
   export GOOGLE_CLOUD_PROJECT="your-project-id"
   export GOOGLE_CLOUD_REGION="us-central1"
   export GCS_BUCKET_NAME="your-bucket-name"

   chmod +x scripts/setup_gcp.sh
   ./scripts/setup_gcp.sh
   ```

2. **Instalar dependÃªncias**:
   ```bash
   uv sync
   ```

3. **Treinar modelo**:
   ```bash
   python examples/train_lstm_vae_gcp.py \
     --data-path data/your_data.csv \
     --model-name my-model \
     --epochs 100
   ```

### ğŸ“ˆ Monitoramento

- **MLflow**: Tracking de experimentos e mÃ©tricas
- **TensorBoard**: VisualizaÃ§Ã£o de treinamento
- **Cloud Logging**: Logs centralizados
- **Cloud Monitoring**: MÃ©tricas e alertas

### ğŸ’° Estimativa de Custos

| ServiÃ§o | Custo/Hora | Uso Estimado | Custo Mensal |
|----------|------------|--------------|--------------|
| Vertex AI (n1-standard-4 + T4) | $0.47 | 10 horas | $4.70 |
| Cloud Storage | $0.02/GB | 100 GB | $2.00 |
| Cloud Build | $0.003/min | 30 min | $0.09 |
| **Total** | - | - | **~$6.79** |

*Estimativas baseadas em uso moderado. Custos reais podem variar.*

## ğŸ“ Estrutura do Projeto

```
petrobras-offshore-wells-anomaly-detection-control-charts/
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ ğŸ“ gcp/                    # â˜ï¸ IntegraÃ§Ã£o Google Cloud
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py              # ConfiguraÃ§Ã£o GCP
â”‚   â”‚   â”œâ”€â”€ auth.py                # AutenticaÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ storage.py             # Cloud Storage
â”‚   â”‚   â”œâ”€â”€ vertex_ai.py           # Vertex AI
â”‚   â”‚   â”œâ”€â”€ training.py            # AI Platform Training
â”‚   â”‚   â””â”€â”€ mlflow_integration.py  # MLflow + GCS
â”‚   â”œâ”€â”€ ğŸ“ models/                 # Modelos de ML
â”‚   â”œâ”€â”€ ğŸ“ data/                   # Processamento de dados
â”‚   â”œâ”€â”€ ğŸ“ utils/                  # UtilitÃ¡rios
â”‚   â””â”€â”€ ğŸ“ evaluation/             # AvaliaÃ§Ã£o de modelos
â”œâ”€â”€ ğŸ“ examples/                   # Exemplos de uso
â”‚   â””â”€â”€ train_lstm_vae_gcp.py     # ğŸš€ Treinamento na nuvem
â”œâ”€â”€ ğŸ“ notebooks/                  # Notebooks Marimo
â”œâ”€â”€ ğŸ“ data/                       # Datasets
â”œâ”€â”€ ğŸ“ scripts/                    # Scripts de automaÃ§Ã£o
â”‚   â””â”€â”€ setup_gcp.sh              # ğŸš€ Setup automÃ¡tico GCP
â”œâ”€â”€ ğŸ“ docker/                     # ContainerizaÃ§Ã£o
â”‚   â””â”€â”€ mlflow.Dockerfile         # MLflow server
â”œâ”€â”€ ğŸ“ .github/workflows/          # CI/CD
â”‚   â””â”€â”€ gcp-training.yml          # ğŸš€ Pipeline de treinamento
â”œâ”€â”€ ğŸ“ docs/                       # DocumentaÃ§Ã£o
â”œâ”€â”€ ğŸ“„ gcp-config.yaml            # âš™ï¸ ConfiguraÃ§Ã£o GCP
â”œâ”€â”€ ğŸ“„ env.example                 # ğŸ“ VariÃ¡veis de ambiente
â”œâ”€â”€ ğŸ“„ mlflow-requirements.txt     # ğŸ“¦ Requirements MLflow
â”œâ”€â”€ ğŸ“„ pyproject.toml             # ğŸ“¦ ConfiguraÃ§Ã£o do projeto
â””â”€â”€ ğŸ“„ README.md                   # ğŸ“š Este arquivo
```

## âš¡ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### ğŸš€ Setup AutomÃ¡tico Completo

Para uma configuraÃ§Ã£o completa e automÃ¡tica do ambiente de desenvolvimento:

#### ğŸ”Œ **1. Instalar ExtensÃµes do VS Code/Cursor**
```bash
# Linux/macOS
chmod +x scripts/install_extensions.sh
./scripts/install_extensions.sh

# Windows (PowerShell)
.\scripts\install_extensions.ps1

# Cross-platform (Python)
python scripts/install_extensions.py
```

#### ğŸ **2. Configurar Ambiente Python**
```bash
# Clone o repositÃ³rio
git clone https://github.com/RafaelAlvesTech/petrobras-offshore-wells-anomaly-detection-control-charts.git
cd petrobras-offshore-wells-anomaly-detection-control-charts

# Instalar uv e criar ambiente
curl -LsSf https://astral.sh/uv/install.sh | sh
uv venv
source .venv/bin/activate  # Linux/Mac
# ou
.venv\Scripts\activate     # Windows

# Instalar dependÃªncias
uv sync
```

#### âš™ï¸ **3. Configurar Pre-commit Hooks**
```bash
uv run pre-commit install
```

### ğŸ†• Por que usar uv, Marimo e Polars?

O **uv** Ã© um gerenciador de pacotes Python moderno que oferece:
- âš¡ **Velocidade**: 10-100x mais rÃ¡pido que pip
- ğŸ”’ **Reproduzibilidade**: Lock files para dependÃªncias exatas
- ğŸ **Compatibilidade**: Funciona com ferramentas existentes
- ğŸš€ **Simplicidade**: Comandos intuitivos e configuraÃ§Ã£o automÃ¡tica

O **Marimo** Ã© uma ferramenta moderna para notebooks Python que oferece:
- ğŸ¯ **Interatividade**: Widgets e componentes reativos
- ğŸ”„ **Reatividade**: AtualizaÃ§Ãµes automÃ¡ticas baseadas em dependÃªncias
- ğŸš€ **Performance**: ExecuÃ§Ã£o rÃ¡pida e eficiente
- ğŸ¤ **ColaboraÃ§Ã£o**: Desenvolvimento em equipe simplificado

O **Polars** Ã© uma biblioteca de manipulaÃ§Ã£o de dados de alta performance que oferece:
- âš¡ **Velocidade**: 10-100x mais rÃ¡pido que Pandas para operaÃ§Ãµes complexas
- ğŸ”„ **ParalelizaÃ§Ã£o**: Processamento automÃ¡tico em mÃºltiplos nÃºcleos
- ğŸ **Sintaxe Familiar**: API similar ao Pandas para fÃ¡cil migraÃ§Ã£o
- ğŸš€ **MemÃ³ria Eficiente**: Uso otimizado de memÃ³ria para grandes datasets

### ğŸ“‹ PrÃ©-requisitos
- Python 3.11+
- uv (gerenciador de pacotes Python moderno)
- Marimo (notebooks interativos Python)
- Polars (manipulaÃ§Ã£o de dados de alta performance)
- Docker (opcional)
- Git

### ğŸš€ InstalaÃ§Ã£o RÃ¡pida

```bash
# 1. Clone o repositÃ³rio
git clone https://github.com/RafaelAlvesTech/petrobras-offshore-wells-anomaly-detection-control-charts.git
cd petrobras-offshore-wells-anomaly-detection-control-charts

# 2. Instale o uv (se ainda nÃ£o tiver)
curl -LsSf https://astral.sh/uv/install.sh | sh
# ou via pip
pip install uv

# 3. Instale o Marimo (notebooks interativos)
uv add marimo

# 4. Instale o Polars (manipulaÃ§Ã£o de dados de alta performance)
uv add polars

# 5. Crie e ative o ambiente virtual com uv
uv venv
source .venv/bin/activate  # Linux/Mac
# ou
.venv\Scripts\activate     # Windows

# 6. Instale as dependÃªncias
uv pip install -r requirements.txt
# ou sincronize o projeto (recomendado)
uv sync
```

# 7. Configure as variÃ¡veis de ambiente
cp .env.example .env
# Edite o arquivo .env com suas configuraÃ§Ãµes
```

### ğŸ³ Com Docker

```bash
# Build da imagem
docker build -t anomaly-detection .

# Executar o container
docker run -p 8000:8000 anomaly-detection
```

### ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

```bash
# Instalar pre-commit hooks
uv run pre-commit install

# Executar testes
uv run pytest

# Executar linting
uv run ruff check .

# Iniciar Marimo (notebooks interativos)
uv run marimo edit

# Benchmark de performance (Polars vs Pandas)
uv run python -c "import polars as pl; print('Polars version:', pl.__version__)"

# Atualizar dependÃªncias
uv sync --upgrade

# Verificar dependÃªncias desatualizadas
uv sync --check
```

### ğŸ¯ **ExtensÃµes Recomendadas**
O projeto inclui scripts automÃ¡ticos para instalar as extensÃµes essenciais baseadas nas suas configuraÃ§Ãµes pessoais do VSCode:

| Categoria | ExtensÃµes | DescriÃ§Ã£o |
|-----------|-----------|-----------|
| ğŸ **Python** | ms-python.python, ms-python.vscode-pylance, ms-python.debugpy, ms-python.isort, charliermarsh.ruff | Desenvolvimento Python completo |
| ğŸ“Š **Data Science** | ms-toolsai.jupyter, ms-toolsai.jupyter-keymap | Notebooks Jupyter e Marimo |
| ğŸ”§ **Dev Tools** | ms-vscode.vscode-json, yzhang.markdown-all-in-one, esbenp.prettier-vscode | Suporte a JSON, Markdown e formataÃ§Ã£o |
| ğŸ³ **Docker** | ms-azuretools.vscode-docker, ms-kubernetes-tools.vscode-kubernetes-tools | ContainerizaÃ§Ã£o e Kubernetes |
| ğŸ”„ **Git** | eamodio.gitlens, donjayamanne.githistory, github.vscode-github-actions | Git supercharged e GitHub Actions |
| ğŸ¨ **Themes** | pkief.material-icon-theme, github.github-vscode-theme, johnpapa.vscode-peacock | Temas e cores personalizadas |
| ğŸ§ª **Testing** | littlefoxteam.vscode-python-test-adapter, firsttris.vscode-jest-runner | Test runners Python e JavaScript |
| ğŸš€ **AI** | GitHub.copilot, GitHub.copilot-chat, visualstudioexptteam.vscodeintellicode | Assistente de IA e IntelliCode |
| ğŸ” **Code Quality** | sonarsource.sonarlint-vscode, streetsidesoftware.code-spell-checker | AnÃ¡lise de cÃ³digo e spell checker |
| ğŸ› ï¸ **Utilities** | chakrounanas.turbo-console-log, gruntfuggly.todo-tree, wallabyjs.quokka-vscode | Ferramentas de produtividade |

## ğŸ“ˆ Metodologia

### ğŸ”„ CRISP-DM Adaptado

```mermaid
graph TD
    A[Entendimento do NegÃ³cio] --> B[Entendimento dos Dados]
    B --> C[PreparaÃ§Ã£o dos Dados]
    C --> D[Modelagem]
    D --> E[AvaliaÃ§Ã£o]
    E --> F[Deployment]
    F --> G[Monitoramento]
```

### ğŸ“Š Fases do Projeto

| Fase | DuraÃ§Ã£o | Atividades Principais |
|------|---------|----------------------|
| ğŸ¯ **Fase 1** | Set-Out/2025 | RevisÃ£o bibliogrÃ¡fica, EDA inicial |
| ğŸ”§ **Fase 2** | Nov-Dez/2025 | PrÃ©-processamento, engenharia de atributos |
| ğŸ¤– **Fase 3** | Jan-Abr/2026 | ImplementaÃ§Ã£o e treinamento dos modelos |
| ğŸ“Š **Fase 4** | Mai-Jun/2026 | AvaliaÃ§Ã£o, interpretabilidade |
| ğŸš€ **Fase 5** | Jul/2026 | Prototipagem, MLOps |
| ğŸ“ **Fase 6** | Ago/2026 | DocumentaÃ§Ã£o, relatÃ³rio final |

## ğŸ“… Cronograma

### ğŸ“… VisÃ£o Geral (12 meses)

```mermaid
gantt
    title Cronograma do Projeto PIBIC
    dateFormat  YYYY-MM-DD
    section Fase 1
    RevisÃ£o BibliogrÃ¡fica    :         des1, 2025-09-01, 2025-10-31
    EDA Inicial             :         des2, 2025-10-01, 2025-10-31
    section Fase 2
    PrÃ©-processamento       :         des3, 2025-11-01, 2025-12-31
    Engenharia de Atributos :         des4, 2025-12-01, 2025-12-31
    section Fase 3
    Modelo 1 (LSTM-VAE)     :         des5, 2026-01-01, 2026-02-28
    Modelo 2 (TranAD)       :         des6, 2026-02-01, 2026-03-31
    Modelo 3 (ECOD)         :         des7, 2026-03-01, 2026-04-30
    section Fase 4
    AvaliaÃ§Ã£o               :         des8, 2026-05-01, 2026-06-30
    section Fase 5
    Prototipagem            :         des9, 2026-07-01, 2026-07-31
    section Fase 6
    DocumentaÃ§Ã£o            :         des10, 2026-08-01, 2026-08-31
```

### ğŸ“‹ Marcos Principais

- [ ] **MÃªs 2 (Out/2025)**: EDA completa e dicionÃ¡rio de dados
- [ ] **MÃªs 4 (Dez/2025)**: Dataset limpo e prÃ©-processado
- [ ] **MÃªs 8 (Abr/2026)**: 3+ modelos implementados e treinados
- [ ] **MÃªs 10 (Jun/2026)**: AvaliaÃ§Ã£o comparativa completa
- [ ] **MÃªs 11 (Jul/2026)**: ProtÃ³tipo funcional
- [ ] **MÃªs 12 (Ago/2026)**: RelatÃ³rio final PIBIC

## ğŸ¯ Objetivos SMART

### ğŸ¯ Objetivo Principal
**Investigar, implementar e avaliar a eficÃ¡cia de modelos inovadores de ML/DL para detecÃ§Ã£o de anomalias em sÃ©ries temporais multivariadas do dataset 3W.**

### ğŸ“Š Key Results (KRs)

| KR | DescriÃ§Ã£o | Prazo | Status |
|----|-----------|-------|--------|
| **KR1** | AnÃ¡lise exploratÃ³ria completa e prÃ©-processamento | MÃªs 4 | ğŸ”„ Em andamento |
| **KR2** | ImplementaÃ§Ã£o de 3+ modelos SOTA | MÃªs 8 | â³ Pendente |
| **KR3** | AnÃ¡lise comparativa e identificaÃ§Ã£o do melhor modelo | MÃªs 10 | â³ Pendente |
| **KR4** | ProtÃ³tipo bÃ¡sico containerizado | MÃªs 11 | â³ Pendente |
| **KR5** | RelatÃ³rio final PIBIC e documentaÃ§Ã£o | MÃªs 12 | â³ Pendente |

## ğŸ”¬ Modelos Implementados

### ğŸ† Modelos Selecionados (SOTA - Ãšltimos 3 anos)

| Modelo | Tipo | CaracterÃ­sticas | Status |
|--------|------|----------------|--------|
| **TranAD** | Transformer | DependÃªncias temporais longas | ğŸ”„ Em implementaÃ§Ã£o |
| **LSTM-VAE** | RNN + Autoencoder | Modelagem de sequÃªncias | ğŸ”„ Em implementaÃ§Ã£o |
| **USAD** | Autoencoder Adversarial | Treinamento rÃ¡pido | â³ Pendente |
| **ECOD** | NÃ£o-paramÃ©trico | InterpretÃ¡vel, escalÃ¡vel | â³ Pendente |


### ğŸ¯ Foco Especial: DetecÃ§Ã£o de Anomalias

- **Features especÃ­ficas**: Taxas de variaÃ§Ã£o de pressÃ£o/vazÃ£o
- **CorrelaÃ§Ãµes cruzadas**: RelaÃ§Ãµes entre mÃºltiplos sensores
- **AnÃ¡lise temporal**: PadrÃµes de evoluÃ§Ã£o das anomalias
- **Processamento eficiente**: Uso do Polars para anÃ¡lise de grandes volumes de dados em tempo real

## ğŸ“Š MÃ©tricas de AvaliaÃ§Ã£o

### ğŸ¯ MÃ©tricas Principais

| MÃ©trica | DescriÃ§Ã£o | ImportÃ¢ncia |
|---------|-----------|-------------|
| **AUC-PR** | Ãrea sob curva Precision-Recall | Alta (dados desbalanceados) |
| **F1-Score** | MÃ©dia harmÃ´nica de precisÃ£o e recall | Alta |
| **Precision@k** | PrecisÃ£o nos top-k prediÃ§Ãµes | MÃ©dia |
| **Recall@k** | Recall nos top-k prediÃ§Ãµes | MÃ©dia |

### ğŸ“ˆ Baselines de ComparaÃ§Ã£o

- **Isolation Forest**: Algoritmo clÃ¡ssico de detecÃ§Ã£o de outliers
- **One-Class SVM**: MÃ©todo de separaÃ§Ã£o de classes
- **LOF (Local Outlier Factor)**: DetecÃ§Ã£o baseada em densidade local

## ğŸš€ Deployment

### ğŸ³ ContainerizaÃ§Ã£o

```dockerfile
# Dockerfile exemplo
FROM python:3.9-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
EXPOSE 8000
CMD ["python", "src/api/main.py"]
```

### ğŸŒ API REST

```python
# Exemplo de endpoint
POST /api/v1/predict
{
    "data": [[timestamp, pressure, temperature, flow, vibration]],
    "model": "lstm-vae"
}

Response:
{
    "anomaly_score": 0.85,
    "is_anomaly": true,
    "confidence": 0.92
}
```

### ğŸ”„ CI/CD Pipeline

```yaml
# .github/workflows/ci.yml
name: CI/CD Pipeline
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Run tests
        run: pytest
      - name: Build Docker image
        run: docker build -t anomaly-detection .
```

## ğŸ“š DocumentaÃ§Ã£o

### ğŸ“– Documentos DisponÃ­veis

- [ğŸ“‹ README.md](README.md) - Este arquivo
- [ğŸš€ Setup Guide](docs/setup-guide.md) - Guia completo de configuraÃ§Ã£o
- [ğŸ“Š Dataset Documentation](docs/dataset.md) - DocumentaÃ§Ã£o do dataset 3W
- [ğŸ”§ API Reference](docs/api.md) - ReferÃªncia da API
- [ğŸ¤– Model Documentation](docs/models.md) - DocumentaÃ§Ã£o dos modelos
- [ğŸ“ˆ Results](docs/results.md) - Resultados e anÃ¡lises
- [ğŸ““ Marimo Notebooks](notebooks/) - Notebooks interativos para EDA e experimentos

### ğŸ“ RelatÃ³rios

- [ğŸ“Š RelatÃ³rio PIBIC](docs/pibic-report.md) - RelatÃ³rio final do projeto
- [ğŸ“ˆ ApresentaÃ§Ã£o](docs/presentation.md) - Slides da apresentaÃ§Ã£o
- [ğŸ”¬ Metodologia](docs/methodology.md) - Detalhes metodolÃ³gicos

## ğŸ¤ ContribuiÃ§Ã£o

### ğŸ‘¥ Como Contribuir

1. **Fork** o projeto
2. **Clone** o repositÃ³rio
3. **Crie** uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
4. **Commit** suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
5. **Push** para a branch (`git push origin feature/AmazingFeature`)
6. **Abra** um Pull Request

### ğŸ“‹ PadrÃµes de ContribuiÃ§Ã£o

- **Commits**: Use [Conventional Commits](https://www.conventionalcommits.org/)
- **CÃ³digo**: Siga as diretrizes PEP 8 para Python
- **DocumentaÃ§Ã£o**: Mantenha o README atualizado
- **Testes**: Adicione testes para novas funcionalidades
- **DependÃªncias**: Use `uv add <package>` para adicionar novas dependÃªncias
- **Ambiente**: Sempre use `uv sync` para sincronizar o ambiente
- **Notebooks**: Use Marimo para desenvolvimento interativo e colaborativo
- **Dados**: Use Polars para operaÃ§Ãµes de dados de alta performance

### ğŸ› Reportando Bugs

- Use o template de issue para bugs
- Inclua informaÃ§Ãµes sobre o ambiente
- Adicione logs e screenshots quando relevante

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ™ Agradecimentos

- **Petrobras** pelo dataset 3W
- **CNPq** pelo suporte via PIBIC
- **Orientador** pela orientaÃ§Ã£o acadÃªmica
- **Comunidade open source** pelas ferramentas utilizadas

## ğŸ“ Contato

- **Autor**: [Rafael Alves]
- **Email**: [rafaelpereiraalves@ufba.br]
- **GitHub**: [@RafaelAlvesTech](https://github.com/RafaelAlvesTech)
- **LinkedIn**: [@rafaelalvestech](https://linkedin.com/in/rafaelalvestech)

---

<div align="center">

**â­ Se este projeto foi Ãºtil para vocÃª, considere dar uma estrela! â­**

[![GitHub stars](https://img.shields.io/github/stars/RafaelAlvesTech/petrobras-offshore-wells-anomaly-detection-control-charts?style=social)](https://github.com/RafaelAlvesTech/petrobras-offshore-wells-anomaly-detection-control-charts/stargazers)
[![GitHub forks](https://img.shields.io/github/forks/RafaelAlvesTech/petrobras-offshore-wells-anomaly-detection-control-charts?style=social)](https://github.com/RafaelAlvesTech/petrobras-offshore-wells-anomaly-detection-control-charts/network/members)
[![GitHub issues](https://img.shields.io/github/issues/RafaelAlvesTech/petrobras-offshore-wells-anomaly-detection-control-charts)](https://github.com/RafaelAlvesTech/petrobras-offshore-wells-anomaly-detection-control-charts/issues)

</div>
